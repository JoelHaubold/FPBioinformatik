Building DAG of jobs...
Using shell: /usr/bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	kallisto_index
	1	kallisto_quant
	2

[Thu Dec 13 14:34:39 2018]
rule kallisto_index:
    input: Tests/ref/genome.chr21.fa
    output: genome.idx
    jobid: 1

[Thu Dec 13 14:36:19 2018]
Finished job 1.
1 of 2 steps (50%) done

[Thu Dec 13 14:36:19 2018]
rule kallisto_quant:
    input: genome.idx, Tests/reads/a.chr21.1.fq, Tests/reads/a.chr21.2.fq
    output: quantOutput
    jobid: 0

Terminating processes on user request, this might take some time.
[Thu Dec 13 14:37:00 2018]
Error in rule kallisto_quant:
    jobid: 0
    output: quantOutput

RuleException:
CalledProcessError in line 19 of /home/dickel00/FP/Bioinfo/FPBioinformatik/Snakefile:
Command ' set -euo pipefail;  kallisto quant -i genome.idx -o quantOutput Tests/reads/a.chr21.1.fq Tests/reads/a.chr21.2.fq ' died with <Signals.SIGINT: 2>.
  File "/home/dickel00/FP/Bioinfo/FPBioinformatik/Snakefile", line 19, in __rule_kallisto_quant
  File "/home/dickel00/miniconda3/envs/snakemake-tutorial/lib/python3.6/concurrent/futures/thread.py", line 56, in run
Removing output files of failed job kallisto_quant since they might be corrupted:
quantOutput
Complete log: /home/dickel00/FP/Bioinfo/FPBioinformatik/.snakemake/log/2018-12-13T143439.327984.snakemake.log
